<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
    <title>Capturing and Using Scientific Data Provenance</title>
    <link rel="stylesheet" type="text/css"
	  href="../research-style.css" >
    <meta http-equiv="Content-Type" content="text/html;charset=ISO-8859-1"> 
  </head>

  <body bgcolor="#FFFFFF" link="#0000FF" alink="#0000FF" vlink="#8800FF" text="#000000">

<h1>Capturing and Using Scientific Data Provenance</h1>
<table width="100%">
<tr>
<td width="33%">
Barbara Lerner<br>
Elizabeth Fong<br>
Mount Holyoke College
</td>
<td width="33%">
Emery Boose<br>
Aaron Ellison<br>
Matt Lau<br>
Harvard Forest
</td>
<td width="33%">
Margo Seltzer<br>
University of British Columbia
</td>
<!--<td><a
  href="http://harvardforest.fas.harvard.edu/education/reu/reu.html"><img
  src="REU2018.jpg" alt="Harvard Forest REU" width="196" height="92"></a></td>-->
</tr>
</table>
<table width="100%">
<tr>
<td width="33%">
Thomas Pasquier<br>
University of Bristol
</td>
<td width="33%">
Joe Wonsil<br>
Carthage College
</td>
<td width="33%">
Orenna Brand<br>
Columbia University
</td>
</tr>

</table>

<h2>Introduction to Data Provenance</h2>

<p>
Technology continues to change the way that scientists work.  Nearly
all scientific data are analyzed with computers and increasingly data
are collected directly in electronic form.  A good example is provided
by sensor networks, which may use electronic sensors and wireless
networks to collect vast quantities of data at a very fast rate. 
Scientific programs, ranging
from Excel spreadsheets to supercomputer applications, manipulate the
collected data to produce scientific results.  Scientists can then
disseminate both the raw and processed data quickly and to a broad,
unknown audience by publishing it on their websites. </p>

<p align="center"><img src="figures/ScientificDataProcessing.png" width="747"
	height="149" alt="Data processing workflow"></p>

<p>
Good science requires more than results.  It requires reproducibility,
verifiability and authentication.  Reproducibility is necessary to
ensure that the results are not an accidental outcome, but the result
of genuine, carefully-performed experimentation and analysis.
Verifiability is necessary to assure that the results really did
derive from the data, even if reproducing the experiment is not a
viable option.  Finally, authentication is necessary to believe that
the raw data used in the scientific work is itself valid.  Without
confidence in these issues, the credibility of data posted on the
Internet has the same level as the typical Wikipedia article.</p>

<p>
For example, data may be collected by sensors and downloaded to a
computer,
perhaps run through some scripts to perform calibration and cleaning,
posting the results for public use on a website, without a scientist
checking their validity.  What can go wrong?  An anemometer might
freeze in an icestorm, reporting a windspeed of 0 incorrectly.  A
sensor might slip out of calibration over time, but the amount of
slippage will remain unknown until the sensor is shipped back to the
manufacturer for calibration tests, most likely long after the data
have been made publicly available.  Bugs in the software that processes
the data may lead to incorrect conclusions.  And so on.
With the pace at which
sensors produce data and programs manipulate data, it is clear that
documentation of the data's provenance itself must be automated, so
that there can be some hope of understanding the data and correcting
for errors that arise in its collection or handling.
</p>

<hr>

<ul>
<li> <a href="project_overview.html">Project overview</a>
<li> <a href="tools.html">Tools that use provenance</a>
<li> <a href="ddg.html">Representing provenance with a
    graph</a>
<li> <a href="RDataTracker.html">Collecting provenance from R scripts with
    RDataTracker</a>
<li> <a href="DDGExplorer.html">Viewing provenance with provViz</a>
<li> <a href="publications.html">Papers and presentations</a>
<li> <a
href="software.html">Software 
Download</a>
</ul>

<hr>

<p>If you are an undergraduate interested in an interdisciplinary
  project involving computer science and ecology, join us for the
  <a
  href="http://harvardforest.fas.harvard.edu/education/reu/reu.html">
  Summer Research Program (REU) at Harvard Forest</a>!</p> 

<p> We have been fortunate to have had many terrific REU students work
  on this and related projects:</p>
<ul>
<li> Cory Teshera-Sterne, Mount Holyoke Colege
<li> Morgan Vigil, Westmont College
<li> Sofiya Taskova, Mount Holyoke College
<li> Andy Kaldunski, Ripon College
<li> Garrett Rosenblatt, University of Rochester
<li> Miruna Oprescu, Harvard University
<li> Yujia Zhou, Dickinson College
<li> Shay Adams, Mount Holyoke College
<li> Vasco Carinhas, Universidad de Puerto Rico en Arecibo
<li> Luis Perez, Harvard University
<li> Nikki Hoffler, Mount Holyoke College
<li> Lia Poulos, Mount Holyoke College
<li> Marios Dardas, Holy Cross College
<li> Alex Liu, Amherst College
<li> Moe Pwint Phyu, Mount Holyoke College
<li> Connor Gregorich-Trevor, Grinnell College
<li> Jen Johnson, Middlebury College
<li> Orenna Brand, Columbia University
<li> Joe Wonsil, Carthage College
</ul>
    <p>This material is based upon work supported by the National
    Science Foundation under Awards No. CCR-0205575, CCR-0427071, and
    IIS-0705772, the National Science Foundation REU grants
    DBI-0452254 and DBI-1003938, the Mount Holyoke Center for the 
    Environment, and the Charles Bullard Fellowship at Harvard
    University and is a contribution from the Harvard Forest Long-Term
    Ecological Research (LTER) program.  Any opinions, 
    findings, and conclusions or recommendations expressed in this
    material are those of the authors and do not necessarily reflect
    the views of the National Science Foundation, Harvard University
    or Mount Holyoke College. 
    <hr>
    <address><a
    href="mailto:blerner@mtholyoke.edu">blerner@mtholyoke.edu</a><br>
    October 9, 2018
    </address>
  </body>
</html>
